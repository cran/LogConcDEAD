\subsection{Example 2: 2-d normal data}
\label{sec:eg2d}

<<label=setn2, include=FALSE, echo=FALSE>>=
n <- 500
@ 
For this section, we will generate \Sexpr{n} points from a bivariate
normal distribution with independent components.  Again, we have set
the seed (to 22) for reproducibility.

<<>>=
set.seed(22)
d <- 2
<<setn2>>
x <- matrix(rnorm(n*d),ncol=d)
@ 


\subsubsection{Basic usage}
\label{sec:basic}

The basic command in this package is \code{mlelcd}, which computes
the log-concave maximum likelihood estimate $\hat{f}_n$.  The
\code{verbose} option controls the diagnostic output, which will be
described in more detail below.

<<>>=
out <- mlelcd(x,verbose=200)
@ 

The default \code{print} statement shows the value of the logarithm of
the maximum likelihood estimator at the data points, the number of
iterations of the subgradient algorithm required, and the total number
of function evaluations required to reach convergence.

In the next two subsections, we will describe the input and output in
more detail.

\subsubsection{Input}
The only input required is an $n \times d$ matrix of data points.  One
dimensional (vector) input will be converted to a matrix.  Optionally
a vector of weights \code{w}, corresponding to $(w_1, \ldots, w_n)$ in
\eqref{eq:weights}, may be specified.  By default this is
\[\left(\frac{1}{n}, \ldots, \frac{1}{n}\right),\] which is
appropriate for independent and identically distributed observations.

A starting value \code{y} may be specified for the vector $\left(y_1,
  \ldots, y_n \right)$; by default a kernel
density estimate (using a normal kernel and a diagonal bandwidth
selected using a normal scale rule) is used.  This is performed using
the (internal) function \code{initialy}.

The parameter \code{verbose} controls the degree of diagnostic
information provided by \pkg{SolvOpt}.  The default value, $-1$,
prints nothing.  The value $0$ prints warning messages only.  If the
value is $m > 0$, diagnostic information is printed every $m$th
iteration.  The printed information summarises the progress of the algorithm,
displaying the iteration number, current value of the objective
function, (Euclidean) length of the last step taken, current value of
$\int \exp\{\bar{h}_y(x)\} \, dx$ and (Euclidean) length of the subgradient.
The last column is motivated by the fact that $0$ is a subgradient
only at the minimum of $\sigma$ \citep[Chapter 27]{Rockafellar1997},
and so for smooth functions a small value of the subgradient may be
used as a stopping criterion.  For nonsmooth functions, we may be
close to the minimum even if this value is relatively large, so only
the middle three columns form the basis of our stopping criteria, as described in Section~\ref{sec:stopping}.

The remaining optional arguments are generic parameters of the $r$-algorithm, and 
have already been discussed in Section~\ref{sec:alg}.

\subsubsection{Output}
The output is an object of class \code{\char34LogConcDEAD\char34},
which has the following elements:
<<>>=
names(out)
@ 

The first two components \code{x} and \code{w} give the input data.
The component \code{logMLE} specifies the logarithm of the maximum
likelihood estimator, via its values at the observation points.  In
this example the first 5 elements are shown, corresponding to the
first 5 rows of the data matrix \code{x}.
<<>>=
out$logMLE[1:5]
@ 

As was mentioned in Sections \ref{sec:intro} and \ref{sec:alg}, there
is a triangulation of $C_n = \mathrm{conv}(X_1,\ldots,X_n)$, the
convex hull of the data,  such that
$\log \hat{f}_n$ is affine on each simplex in the triangulation.  Each
simplex in the triangulation is the convex hull of a subset of
$\{X_1,\ldots,X_n\}$ of size $d+1$.  Thus the simplices in the
triangulation may be indexed by a finite set $J$ of $(d+1)$-tuples,
which are available via

<<>>=
out$triang[1:5,]
@ 

For each $j \in J$, there is a corresponding vector $b_j \in \mathbb{R}^d$ 
and $\beta_j \in \mathbb{R}$, which define the affine function which coincides 
with $\log \hat{f}_n$ on the $j$th simplex in the triangulation.  These
values $b_j$ and $\beta_j$ are available in
<<>>=
out$b[1:5,]
out$beta[1:5]
@ 
(In all of the above cases, only the first 5 elements are shown.)
As discussed in \citet{CSS2008}, for each $j \in J$ we may find a
matrix $A_j$ and a vector $\alpha_j$ such that the map $w \mapsto A_jw +
\alpha_j$ maps the unit simplex in $\mathbb{R}^d$ to the $j$th simplex 
in the triangulation.   The inverse of this map, $x \mapsto A_j^{-1} x -
A_j^{-1} \alpha_j$, is required for easy evaluation of the density at a 
point, and for plotting.  The matrix $A_j^{-1}$ is available in \code{out\$verts} and
$A_j^{-1} \alpha_j$ is available in \code{out\$vertsoffset}.  

The \code{\char34LogConcDEAD\char34} object also provides some
diagnostic information on the execution of the \pkg{SolvOpt} routine:
the number of iterations required, the number of function evaluations
needed, the
number of subgradient evaluations required (in a vector
\code{NumberOfEvaluations}), and the minimum value of the objective
function $\sigma$ attained (\code{MinSigma}).

<<>>=
out$NumberOfEvaluations
out$MinSigma
@ 

The indices of simplices in the convex hull $C_n$ are available:
<<>>=
out$chull[1:5,]
@ 
In addition, an outward-pointing normal vector for each face of the
convex hull $C_n$ and an offset point (lying on the face of the convex hull)
may be obtained.  

<<>>=
out$outnorm[1:5,]
out$outoffset[1:5,]
@ 

This information may be used to test whether or not a point lies in $C_n$, 
as $x \in C_n$ if and only if $p^T(x-q) \leq 0$ for every face of the convex hull, 
where $p$ denotes an outward normal and $q$ an offset point.

When $d=1$, the convex hull consists simply of the minimum and maximum
of the data points, and \code{out$outnorm} and \code{out$outoffset} are
\code{NULL}, although \code{out$chull} still takes on the appropriate
values.


\subsection{Graphics}
\label{sec:graphics}
Various aspects of the log-concave maximum likelihood estimator can be
plotted using the \code{plot} command, applied to an object of class \code{\char34LogConcDEAD\char34}. 

The plots are based on interpolation over a grid, which can be
somewhat time-consuming.  As several will be done here, we can save
the results of the interpolation separately, using the function
\code{interplcd}, and use it to make several plots.  The number of
grid points may be specified using the parameter \code{gridlen}.  By
default, \code{gridlen}=100, which is suitable for most plots.  

Where relevant, the colors were obtained by a call to \code{heat_hcl}
in the package \pkg{colorspace} \citep{colorspace}, following the
recommendation of \citet{HMZ2008}. Thanks to Achim Zeileis for this
helpful suggestion.

<<>>=
g <- interplcd(out, gridlen=200)
g1 <- interpmarglcd(out, marg=1)
g2 <- interpmarglcd(out, marg=2)
@ 
The plots in Figure~\ref{fig:2d} show a contour plot of the estimator
and a contour plot of its logarithm for \Sexpr{n} points in 2
dimensions.  Note that the contours of log-concave densities enclose
convex regions. This figure is produced using
<<label=plot:2d, eval=FALSE>>=
par(mfrow=c(1,2), pty="s", cex=0.7) #square plots
plot(out,g=g,addp=FALSE,asp=1)
plot(out,g=g,uselog=TRUE,addp=FALSE,asp=1)
@ 

\begin{figure}[ht!]
  \centering
<<echo=FALSE, results=hide>>=
png(file="LogConcDEAD-fig:2d.png")
<<plot:2d>>
dev.off()
@
\includegraphics[width=\textwidth, clip=TRUE, trim = 0 120 0 100]{LogConcDEAD-fig:2d}
  \caption{Plots based on \Sexpr{n} points from a standard bivariate
  normal distribution}
  \label{fig:2d}

\end{figure}


If $d>1$, we can plot one-dimensional marginals by setting the
\code{marg} parameter.  Note that the marginal densities of a
log-concave density are log-concave (discussed in \citet{CSS2008}, as
a consequence of the theory of \citet{Prekopa1973}).  This is
illustrated by Figure~\ref{fig:2dmarg} using the following code:
<<label=plot:2dmarg, eval=FALSE>>=
par(mfrow=c(1,2), pty="s", cex=0.7) #normal proportions 
plot(out,marg=1,g.marg=g1)
plot(out,marg=2,g.marg=g2)
@ 

\begin{figure}[ht!]
  \centering
<<label=fig:2dmarg,mecho=FALSE,results=hide, fig=TRUE, include=FALSE>>=
<<plot:2dmarg>>
@
  \includegraphics[width=\textwidth, clip=TRUE, trim=0 110 0
  100]{LogConcDEAD-fig:2dmarg}
\caption{Plots of estimated marginal densities based on \Sexpr{n} points from a standard bivariate
  normal distribution}
  \label{fig:2dmarg}
\end{figure}

The plot type is controlled by the argument \code{type}, which may
take the values \code{\char34p\char34} (a perspective plot),
\code{\char34i\char34}, \code{\char34c\char34} or
\code{\char34ic\char34} (colour maps, contours or both), or
\code{\char34r\char34} (a 3d plot using the \pkg{rgl} package
\citep{AdlerMurdoch2007}).  The default plot type is \code{\char34ic\char34}.

The \pkg{rgl} package allows user interaction with the plot (e.g. the
plot can be rotated using the mouse and viewed from different angles).
Although we are unable to demonstrate this feature on paper, Figure~\ref{fig:rgl} shows the type of output produced by \pkg{rgl}, using
the following code:  

<<label=plot:rgl, eval=FALSE>>=
plot(out,g=g,type="r")
@ 
Figure~\ref{fig:rgllog} shows the output produced by setting
\code{uselog = TRUE} to plot on the log
scale.  Here we can clearly see the structure of the log-concave
density estimate. This is produced using the command

<<label=plot:rgllog, eval=FALSE>>=
plot(out,g=g,type="r",uselog=TRUE)
@ 

\begin{figure}[ht!]
  \centering
<<echo=FALSE, results=hide, eval=FALSE>>=
<<plot:rgl>>
par3d(windowRect = c(55,66,311+256, 322+256))
rgl.snapshot(file="rglfig.png")
@ 
\includegraphics[clip=TRUE, trim=0 10 0 60]{rglfig.png}
    \caption{\pkg{rgl} output for Example 2}
  \label{fig:rgl}
\end{figure}

\begin{figure}[ht!]
  \centering
<<echo=FALSE, results=hide, eval=FALSE>>=
<<plot:rgllog>>
par3d(windowRect = c(55,66,311+256, 322+256))
rgl.snapshot(file="rgllog.png")
@ 
\includegraphics[clip=TRUE, trim=0 50 0 80]{rgllog.png}
    \caption{\pkg{rgl} output for Example 2 with \code{uselog=TRUE}}
  \label{fig:rgllog}
\end{figure}

\subsection{Other functions}
\label{sec:usageother}

In this section we will describe the use of the additional functions
\code{rlcd} and \code{dlcd}.

\subsubsection{Sampling from the MLE}
Suppose we wish to estimate a functional of the form $\theta(f) = \int
g(x) f(x) \, dx$, for example the mean or other moments, the
differential entropy $- \int f(x) \log f(x) \,dx$, etc.  Once we have
obtained a density estimate $\hat{f}_n$, such as the log-concave
maximum likelihood estimator, we may use it as the basis for a plug-in
estimate $\hat{\theta}_n = \int g(x) \hat{f}_n(x) \, dx$, which may be
approximated using a simple Monte Carlo procedure even if an analytic
expression is not readily available.  In more detail, we generate a
sample $Z_1, \ldots, Z_N$ drawn from $\hat{f}_n$, and approximate
$\hat{\theta}_n$ by 
\[\tilde{\theta}_n = \frac{1}{N} \sum_{j=1}^N g(Z_j).\]
This requires the ability to sample from $\hat{f}_n$, which may be
achieved given an object of class \code{\char34LogConcDEAD\char34} as follows:
<<>>=
nsamp <- 1000
mysamp <- rlcd(nsamp,out)
@
Details of the function \code{rlcd}, which uses a straightforward
rejection sampling scheme, are given in \citet{CSS2008}.  

Once we have a random sample, plug-in estimation of various
functionals is straightforward.
<<>>=
apply(mysamp,2,mean)
cov(mysamp)
@

\subsubsection{Evaluation of fitted density}

We may evaluate the fitted density at a
point or matrix of points such as
<<>>=
m <- 10
mypoints <- 1.5*matrix(rnorm(m*d),ncol=d)
@ 
using the command

<<>>=
dlcd(mypoints,out)
@ 

Note that, as expected, the density estimate is zero for points
outside the convex hull of the original data.  

The \code{dlcd} function may be used in conjunction with
\code{rlcd} to estimate more complicated functionals such as a
100$(1-\alpha)\%$ highest density region, defined by
\citet{Hyndman1996} as $R_\alpha = \{x \in \mathbb{R}^d: f(x) \geq
f_\alpha\}$, where $f_\alpha$ is the largest constant such that
$\int_{R_\alpha} f(x) \, dx \geq 1-\alpha$.  Using the algorithm
outlined in \citet[][Section 3.2]{Hyndman1996}, it is straightforward
to approximate $f_\alpha$ as follows:

<<>>=
myval <- sort(dlcd(mysamp,out))
alpha <- c(.25,.5,.75)
myval[(1-alpha)*nsamp]

@ 
